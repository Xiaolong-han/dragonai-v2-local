"""æ–‡ä»¶ç³»ç»Ÿå·¥å…· - æ–‡ä»¶è¯»å†™ã€æœç´¢å’Œæ–‡æ¡£è§£æ"""

import base64
import fnmatch
import logging
from pathlib import Path
from typing import Optional, List

from langchain_core.tools import tool

from app.config import settings
from app.core.sandbox import FileSandbox

logger = logging.getLogger(__name__)

IMAGE_EXTENSIONS = frozenset({".png", ".jpg", ".jpeg", ".gif", ".webp"})
IMAGE_MEDIA_TYPES = {
    ".png": "image/png",
    ".jpg": "image/jpeg",
    ".jpeg": "image/jpeg",
    ".gif": "image/gif",
    ".webp": "image/webp",
}

STORAGE_DIR = Path(settings.storage_dir).resolve()


def _resolve_path(file_path: str, for_write: bool = False) -> Path:
    """è§£ææ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨æ²™ç®±éªŒè¯ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        for_write: æ˜¯å¦ç”¨äºå†™å…¥æ“ä½œ
        
    Returns:
        è§£æåçš„ Path å¯¹è±¡
        
    Raises:
        ValueError: è·¯å¾„ä¸åˆæ³•æˆ–åœ¨æ²™ç®±å¤–
    """
    try:
        if for_write:
            return FileSandbox.validate_path_for_write(file_path)
        return FileSandbox.validate_path(file_path)
    except PermissionError as e:
        raise ValueError(str(e))


def _to_virtual_path(path: Path) -> str:
    """å°†ç‰©ç†è·¯å¾„è½¬æ¢ä¸ºè™šæ‹Ÿè·¯å¾„"""
    return FileSandbox.to_virtual_path(path)


def _format_with_line_numbers(lines: List[str], start_line: int = 1) -> str:
    """æ ¼å¼åŒ–å†…å®¹å¹¶æ·»åŠ è¡Œå·"""
    max_line_num = start_line + len(lines) - 1
    line_num_width = len(str(max_line_num))
    
    result = []
    for i, line in enumerate(lines):
        line_num = start_line + i
        result.append(f"{line_num:>{line_num_width}}â†’{line}")
    
    return "\n".join(result)


def _format_size(size: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ["B", "KB", "MB", "GB"]:
        if size < 1024:
            return f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"


@tool
def ls(path: str = "/") -> str:
    """åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚

    ç”¨äºæ¢ç´¢æ–‡ä»¶ç³»ç»Ÿï¼ŒæŸ¥æ‰¾éœ€è¦è¯»å–æˆ–ç¼–è¾‘çš„æ–‡ä»¶ã€‚
    åœ¨ä½¿ç”¨ read_file æˆ– edit_file ä¹‹å‰ï¼Œé€šå¸¸åº”å…ˆä½¿ç”¨æ­¤å·¥å…·ã€‚

    Args:
        path: ç›®å½•è·¯å¾„ï¼Œå¦‚ /documents æˆ– /skillsã€‚
              é»˜è®¤ä¸º "/"ï¼Œæ˜¾ç¤º storage ç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹ã€‚

    Returns:
        ç›®å½•å†…å®¹åˆ—è¡¨ï¼ŒåŒ…å«æ–‡ä»¶åã€ç±»å‹å’Œå¤§å°ä¿¡æ¯ã€‚
    """
    try:
        if path == "/":
            items = _list_dir(STORAGE_DIR)
            return "\n".join(items) if items else "storage ç›®å½•ä¸ºç©º"
        
        resolved = _resolve_path(path)
        
        if not resolved.exists():
            return f"é”™è¯¯ï¼šç›®å½• '{path}' ä¸å­˜åœ¨"
        
        if not resolved.is_dir():
            return f"é”™è¯¯ï¼š'{path}' ä¸æ˜¯ç›®å½•"
        
        items = _list_dir(resolved)
        return "\n".join(items) if items else f"ç›®å½• '{path}' ä¸ºç©º"
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"åˆ—å‡ºç›®å½•æ—¶å‡ºé”™: {e}"


def _list_dir(dir_path: Path) -> List[str]:
    """åˆ—å‡ºç›®å½•å†…å®¹"""
    items = []
    try:
        for child in sorted(dir_path.iterdir()):
            if child.is_dir():
                items.append(f"ğŸ“ {child.name}/")
            else:
                size = child.stat().st_size
                size_str = _format_size(size)
                items.append(f"ğŸ“„ {child.name} ({size_str})")
    except PermissionError:
        items.append("âš ï¸ æ— æƒé™è®¿é—®")
    return items


@tool
def read_file(
    file_path: str,
    offset: int = 0,
    limit: int = 100,
) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹ã€‚

    å¯ä»¥è¯»å–æ–‡æœ¬æ–‡ä»¶å’Œå›¾ç‰‡æ–‡ä»¶ã€‚
    
    å¯¹äºæ–‡æœ¬æ–‡ä»¶ï¼š
    - é»˜è®¤è¯»å–å‰ 100 è¡Œ
    - ä½¿ç”¨ offset å’Œ limit å‚æ•°åˆ†é¡µè¯»å–å¤§æ–‡ä»¶
    - ç»“æœå¸¦æœ‰è¡Œå·ï¼Œä» 1 å¼€å§‹
    
    å¯¹äºå›¾ç‰‡æ–‡ä»¶ï¼ˆ.png, .jpg, .jpeg, .gif, .webpï¼‰ï¼š
    - è¿”å› base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
    - Agent å¯ä»¥ç›´æ¥"çœ‹åˆ°"å›¾ç‰‡å†…å®¹

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ documents/xxx.txt æˆ– /documents/xxx.txtã€‚
        offset: å¼€å§‹è¯»å–çš„è¡Œå·ï¼ˆ0 ç´¢å¼•ï¼‰ï¼Œé»˜è®¤ 0ã€‚
        limit: æœ€å¤šè¯»å–çš„è¡Œæ•°ï¼Œé»˜è®¤ 100ã€‚

    Returns:
        æ–‡ä»¶å†…å®¹ï¼ˆå¸¦è¡Œå·ï¼‰æˆ–é”™è¯¯ä¿¡æ¯ã€‚
    """
    try:
        resolved = _resolve_path(file_path)
        
        if not resolved.exists():
            return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨"
        
        if not resolved.is_file():
            return f"é”™è¯¯ï¼š'{file_path}' ä¸æ˜¯æ–‡ä»¶"
        
        ext = resolved.suffix.lower()
        
        if ext in IMAGE_EXTENSIONS:
            return _read_image_file(resolved)
        
        return _read_text_file(resolved, offset, limit)
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except UnicodeDecodeError:
        return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶æˆ–ç¼–ç ä¸æ”¯æŒ"
    except Exception as e:
        return f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"


def _read_image_file(file_path: Path) -> str:
    """è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶è¿”å› base64 æ•°æ®"""
    mime_type = IMAGE_MEDIA_TYPES.get(file_path.suffix.lower(), "image/png")
    
    with open(file_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")
    
    return f"[å›¾ç‰‡æ–‡ä»¶: {file_path.name}]\n[Base64 æ•°æ®: data:{mime_type};base64,{image_data[:100]}...]"


def _read_text_file(file_path: Path, offset: int, limit: int) -> str:
    """è¯»å–æ–‡æœ¬æ–‡ä»¶"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    if not content.strip():
        return f"æ–‡ä»¶ '{file_path.name}' ä¸ºç©º"
    
    lines = content.splitlines()
    total_lines = len(lines)
    
    if offset >= total_lines:
        return f"é”™è¯¯ï¼šèµ·å§‹è¡Œ {offset} è¶…å‡ºæ–‡ä»¶èŒƒå›´ï¼ˆå…± {total_lines} è¡Œï¼‰"
    
    end_idx = min(offset + limit, total_lines)
    selected_lines = lines[offset:end_idx]
    
    result = []
    result.append(f"æ–‡ä»¶: {file_path.name}")
    result.append(f"æ€»è¡Œæ•°: {total_lines}")
    result.append(f"æ˜¾ç¤º: ç¬¬ {offset + 1} è¡Œ - ç¬¬ {end_idx} è¡Œ")
    result.append("-" * 50)
    result.append(_format_with_line_numbers(selected_lines, offset + 1))
    
    if end_idx < total_lines:
        result.append("")
        result.append(f"... è¿˜æœ‰ {total_lines - end_idx} è¡Œæœªæ˜¾ç¤º ...")
    
    return "\n".join(result)


@tool
def write_file(file_path: str, content: str) -> str:
    """åˆ›å»ºæ–°æ–‡ä»¶å¹¶å†™å…¥å†…å®¹ã€‚

    å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¿”å›é”™è¯¯ã€‚
    å¦‚éœ€ä¿®æ”¹ç°æœ‰æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ edit_file å·¥å…·ã€‚

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ documents/xxx.txt æˆ– /documents/xxx.txtã€‚
        content: è¦å†™å…¥çš„æ–‡æœ¬å†…å®¹ã€‚

    Returns:
        æ“ä½œç»“æœä¿¡æ¯ã€‚
    """
    try:
        resolved = _resolve_path(file_path, for_write=True)
        
        if resolved.exists():
            return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' å·²å­˜åœ¨ã€‚å¦‚éœ€ä¿®æ”¹ï¼Œè¯·å…ˆè¯»å–åä½¿ç”¨ edit_file å·¥å…·ã€‚"
        
        resolved.parent.mkdir(parents=True, exist_ok=True)
        
        with open(resolved, "w", encoding="utf-8") as f:
            f.write(content)
        
        logger.info(f"[SANDBOX] File created: {resolved}")
        virtual_path = _to_virtual_path(resolved)
        return f"æ–‡ä»¶å·²åˆ›å»º: {virtual_path}"
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}"


@tool
def edit_file(
    file_path: str,
    old_string: str,
    new_string: str,
    replace_all: bool = False,
) -> str:
    """ç¼–è¾‘æ–‡ä»¶ï¼Œæ›¿æ¢æŒ‡å®šçš„æ–‡æœ¬å†…å®¹ã€‚

    å¿…é¡»å…ˆä½¿ç”¨ read_file è¯»å–æ–‡ä»¶åæ‰èƒ½ç¼–è¾‘ã€‚
    old_string å¿…é¡»ä¸æ–‡ä»¶ä¸­çš„å†…å®¹å®Œå…¨åŒ¹é…ï¼ˆåŒ…æ‹¬ç©ºæ ¼å’Œç¼©è¿›ï¼‰ã€‚

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ documents/xxx.txt æˆ– /documents/xxx.txtã€‚
        old_string: è¦æŸ¥æ‰¾å’Œæ›¿æ¢çš„æ–‡æœ¬ã€‚å¿…é¡»å®Œå…¨åŒ¹é…ã€‚
        new_string: æ›¿æ¢åçš„æ–°æ–‡æœ¬ã€‚
        replace_all: æ˜¯å¦æ›¿æ¢æ‰€æœ‰åŒ¹é…é¡¹ã€‚é»˜è®¤ Falseï¼Œæ­¤æ—¶ old_string å¿…é¡»å”¯ä¸€ã€‚

    Returns:
        æ“ä½œç»“æœä¿¡æ¯ã€‚
    """
    try:
        resolved = _resolve_path(file_path)
        
        if not resolved.exists():
            return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨"
        
        if not resolved.is_file():
            return f"é”™è¯¯ï¼š'{file_path}' ä¸æ˜¯æ–‡ä»¶"
        
        with open(resolved, "r", encoding="utf-8") as f:
            content = f.read()
        
        if old_string not in content:
            return f"é”™è¯¯ï¼šæœªæ‰¾åˆ°è¦æ›¿æ¢çš„å†…å®¹ã€‚è¯·ç¡®ä¿ old_string ä¸æ–‡ä»¶å†…å®¹å®Œå…¨åŒ¹é…ã€‚"
        
        count = content.count(old_string)
        
        if count > 1 and not replace_all:
            return f"é”™è¯¯ï¼šæ‰¾åˆ° {count} å¤„åŒ¹é…ï¼Œä½† replace_all=Falseã€‚è¯·æä¾›æ›´å…·ä½“çš„ old_string æˆ–è®¾ç½® replace_all=Trueã€‚"
        
        if replace_all:
            new_content = content.replace(old_string, new_string)
            occurrences = count
        else:
            new_content = content.replace(old_string, new_string, 1)
            occurrences = 1
        
        with open(resolved, "w", encoding="utf-8") as f:
            f.write(new_content)
        
        virtual_path = _to_virtual_path(resolved)
        return f"æˆåŠŸæ›¿æ¢ {occurrences} å¤„å†…å®¹: {virtual_path}"
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"ç¼–è¾‘æ–‡ä»¶æ—¶å‡ºé”™: {e}"


@tool
def glob(pattern: str, path: str = "/") -> str:
    """æŸ¥æ‰¾åŒ¹é…æ¨¡å¼çš„æ–‡ä»¶ã€‚

    æ”¯æŒæ ‡å‡† glob æ¨¡å¼ï¼š
    - * åŒ¹é…ä»»æ„å­—ç¬¦
    - ** åŒ¹é…ä»»æ„ç›®å½•
    - ? åŒ¹é…å•ä¸ªå­—ç¬¦

    ç¤ºä¾‹ï¼š
    - **/*.py - æŸ¥æ‰¾æ‰€æœ‰ Python æ–‡ä»¶
    - *.txt - æŸ¥æ‰¾æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰ txt æ–‡ä»¶
    - documents/**/*.md - æŸ¥æ‰¾ documents ç›®å½•ä¸‹çš„æ‰€æœ‰ markdown æ–‡ä»¶

    Args:
        pattern: glob åŒ¹é…æ¨¡å¼ã€‚
        path: æœç´¢çš„èµ·å§‹ç›®å½•ï¼Œé»˜è®¤ä¸º storage æ ¹ç›®å½•ã€‚

    Returns:
        åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    try:
        if pattern.startswith("/"):
            pattern = pattern[1:]
        
        base_dir = STORAGE_DIR if path == "/" else _resolve_path(path)
        
        results = []
        for matched in base_dir.rglob(pattern):
            if matched.is_file():
                relative = matched.relative_to(STORAGE_DIR)
                results.append(f"/storage/{relative.as_posix()}")
        
        if not results:
            return f"æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„æ–‡ä»¶"
        
        return "\n".join(sorted(results))
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"æœç´¢æ–‡ä»¶æ—¶å‡ºé”™: {e}"


@tool
def grep(
    pattern: str,
    path: str = "/",
    glob_pattern: Optional[str] = None,
    output_mode: str = "files_with_matches",
) -> str:
    """åœ¨æ–‡ä»¶ä¸­æœç´¢æ–‡æœ¬å†…å®¹ã€‚

    æœç´¢å­—é¢æ–‡æœ¬ï¼ˆéæ­£åˆ™è¡¨è¾¾å¼ï¼‰ï¼Œè¿”å›åŒ¹é…çš„æ–‡ä»¶æˆ–å†…å®¹ã€‚

    Args:
        pattern: è¦æœç´¢çš„æ–‡æœ¬å†…å®¹ã€‚
        path: æœç´¢çš„èµ·å§‹ç›®å½•ï¼Œé»˜è®¤ä¸º storage æ ¹ç›®å½•ã€‚
        glob_pattern: æ–‡ä»¶è¿‡æ»¤æ¨¡å¼ï¼Œå¦‚ *.py åªæœç´¢ Python æ–‡ä»¶ã€‚
        output_mode: è¾“å‡ºæ¨¡å¼ï¼š
            - "files_with_matches": åªè¿”å›æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼‰
            - "content": è¿”å›åŒ¹é…çš„è¡Œå†…å®¹

    Returns:
        æœç´¢ç»“æœã€‚
    """
    try:
        base_dir = STORAGE_DIR if path == "/" else _resolve_path(path)
        
        results = []
        for file_path in base_dir.rglob("*"):
            if not file_path.is_file():
                continue
            
            if glob_pattern:
                if not fnmatch.fnmatch(file_path.name, glob_pattern):
                    continue
            
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                
                if pattern in content:
                    relative = file_path.relative_to(STORAGE_DIR)
                    virtual_path = f"/storage/{relative.as_posix()}"
                    
                    if output_mode == "files_with_matches":
                        results.append(virtual_path)
                    else:
                        lines = content.splitlines()
                        for i, line in enumerate(lines, 1):
                            if pattern in line:
                                results.append(f"{virtual_path}:{i}: {line.strip()}")
            
            except (UnicodeDecodeError, PermissionError):
                continue
        
        if not results:
            return f"æœªæ‰¾åˆ°åŒ…å« '{pattern}' çš„æ–‡ä»¶"
        
        return "\n".join(results)
        
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"æœç´¢æ—¶å‡ºé”™: {e}"


@tool
async def read_pdf(file_path: str, start_page: int = 1, end_page: Optional[int] = None, use_ocr: bool = False) -> str:
    """è¯»å– PDF æ–‡ä»¶å†…å®¹ã€‚

    å½“ç”¨æˆ·ä¸Šä¼  PDF æ–‡ä»¶å¹¶éœ€è¦æå–æ–‡å­—å†…å®¹æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    æ”¯æŒåˆ†é¡µè¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§è¯»å–è¿‡å¤šå†…å®¹ã€‚
    
    å¯¹äºæ‰«æç‰ˆ PDFï¼ˆå›¾ç‰‡å‹ PDFï¼‰ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æç¤ºä½¿ç”¨ OCR æ¨¡å¼ã€‚

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ documents/xxx.pdf æˆ– /documents/xxx.pdfã€‚
        start_page: å¼€å§‹é¡µç ï¼Œä» 1 å¼€å§‹ï¼Œé»˜è®¤ä¸º 1ã€‚
        end_page: ç»“æŸé¡µç ï¼Œä¸æŒ‡å®šåˆ™è¯»å–åˆ°æœ€åä¸€é¡µã€‚
        use_ocr: æ˜¯å¦ä½¿ç”¨ OCR æ¨¡å¼å¤„ç†æ‰«æç‰ˆ PDFã€‚é»˜è®¤ Falseã€‚
                 å½“ PDF æ˜¯æ‰«æå›¾ç‰‡æ—¶ï¼Œè®¾ç½®ä¸º True å¯æå–æ–‡å­—ã€‚

    Returns:
        PDF æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹ï¼ŒåŒ…å«é¡µç æ ‡è®°ã€‚
    """
    try:
        resolved = _resolve_path(file_path)
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    
    if not resolved.exists():
        return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨"
    
    if resolved.suffix.lower() != ".pdf":
        return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸æ˜¯ PDF æ ¼å¼"
    
    try:
        from pypdf import PdfReader
        
        reader = PdfReader(str(resolved))
        total_pages = len(reader.pages)
        
        if start_page < 1:
            start_page = 1
        if start_page > total_pages:
            return f"é”™è¯¯ï¼šèµ·å§‹é¡µç  {start_page} è¶…å‡ºèŒƒå›´ï¼ŒPDF å…± {total_pages} é¡µ"
        
        if end_page is None:
            end_page = total_pages
        elif end_page > total_pages:
            end_page = total_pages
        
        content_parts = []
        content_parts.append(f"PDF æ–‡ä»¶: {resolved.name}")
        content_parts.append(f"æ€»é¡µæ•°: {total_pages}")
        content_parts.append(f"è¯»å–èŒƒå›´: ç¬¬ {start_page} é¡µ - ç¬¬ {end_page} é¡µ")
        content_parts.append("-" * 50)
        
        total_text = ""
        for page_num in range(start_page - 1, end_page):
            page = reader.pages[page_num]
            text = page.extract_text()
            if text.strip():
                content_parts.append(f"\n=== ç¬¬ {page_num + 1} é¡µ ===\n")
                content_parts.append(text)
                total_text += text
        
        if not total_text.strip() or use_ocr:
            if not use_ocr and not total_text.strip():
                content_parts.append("\nâš ï¸ æ£€æµ‹åˆ°è¿™æ˜¯æ‰«æç‰ˆ PDFï¼ˆæ— æ–‡æœ¬å±‚ï¼‰")
                content_parts.append("è¯·è®¾ç½® use_ocr=True æ¥ä½¿ç”¨ OCR æå–æ–‡å­—")
                return "\n".join(content_parts)
            
            if use_ocr:
                return await _ocr_pdf(resolved, start_page, end_page)
        
        return "\n".join(content_parts)
        
    except Exception as e:
        return f"è¯»å– PDF æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"


async def _ocr_pdf(file_path: Path, start_page: int, end_page: int) -> str:
    """ä½¿ç”¨ OCR å¤„ç†æ‰«æç‰ˆ PDF"""
    try:
        import fitz
        from app.llm.model_factory import ModelFactory
        from app.utils.image_utils import build_openai_image_content
        import tempfile
        import base64
        
        doc = fitz.open(str(file_path))
        total_pages = len(doc)
        
        content_parts = []
        content_parts.append(f"PDF æ–‡ä»¶: {file_path.name}")
        content_parts.append(f"æ€»é¡µæ•°: {total_pages}")
        content_parts.append(f"OCR è¯»å–èŒƒå›´: ç¬¬ {start_page} é¡µ - ç¬¬ {end_page} é¡µ")
        content_parts.append("-" * 50)
        
        model = ModelFactory.get_vision_model(is_ocr=True)
        
        for page_num in range(start_page - 1, min(end_page, total_pages)):
            page = doc[page_num]
            mat = fitz.Matrix(2.0, 2.0)
            pix = page.get_pixmap(matrix=mat)
            
            img_data = pix.tobytes("png")
            img_base64 = base64.b64encode(img_data).decode("utf-8")
            img_url = f"data:image/png;base64,{img_base64}"
            
            prompt = "è¯·æå–è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼ã€‚åªè¾“å‡ºæ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜ã€‚"
            content = build_openai_image_content(img_url, prompt)
            messages = [{"role": "user", "content": content}]
            
            result = await model.ainvoke(messages)
            
            content_parts.append(f"\n=== ç¬¬ {page_num + 1} é¡µ ===\n")
            content_parts.append(result.content)
        
        doc.close()
        return "\n".join(content_parts)
        
    except ImportError:
        return "é”™è¯¯ï¼šOCR æ¨¡å¼éœ€è¦å®‰è£… PyMuPDF åº“ã€‚è¯·è¿è¡Œ: pip install PyMuPDF"
    except Exception as e:
        return f"OCR å¤„ç† PDF æ—¶å‡ºé”™: {str(e)}"


@tool
async def read_word(file_path: str) -> str:
    """è¯»å– Word æ–‡æ¡£(.docx)å†…å®¹ã€‚

    å½“ç”¨æˆ·ä¸Šä¼  Word æ–‡æ¡£å¹¶éœ€è¦æå–æ–‡å­—å†…å®¹æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    æ”¯æŒè¯»å–æ–‡æ¡£æ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ç­‰å†…å®¹ã€‚

    Args:
        file_path: Word æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ documents/xxx.docx æˆ– /documents/xxx.docxã€‚

    Returns:
        Word æ–‡æ¡£çš„æ–‡æœ¬å†…å®¹ï¼ŒåŒ…å«ç»“æ„æ ‡è®°ã€‚
    """
    try:
        resolved = _resolve_path(file_path)
    except ValueError as e:
        return f"é”™è¯¯ï¼š{e}"
    
    if not resolved.exists():
        return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨"
    
    if resolved.suffix.lower() not in [".docx", ".doc"]:
        return f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸æ˜¯ Word æ–‡æ¡£æ ¼å¼"
    
    if resolved.suffix.lower() == ".doc":
        return "é”™è¯¯ï¼šæš‚ä¸æ”¯æŒæ—§ç‰ˆ .doc æ ¼å¼ï¼Œè¯·è½¬æ¢ä¸º .docx æ ¼å¼åé‡è¯•"
    
    try:
        from docx import Document
        
        doc = Document(str(resolved))
        
        content_parts = []
        content_parts.append(f"Word æ–‡æ¡£: {resolved.name}")
        content_parts.append("-" * 50)
        
        for para in doc.paragraphs:
            if para.text.strip():
                style_name = para.style.name if para.style else "Normal"
                if "Heading" in style_name:
                    content_parts.append(f"\n## {para.text}")
                else:
                    content_parts.append(para.text)
        
        if doc.tables:
            content_parts.append("\n" + "=" * 50)
            content_parts.append("è¡¨æ ¼å†…å®¹:")
            content_parts.append("=" * 50)
            
            for table_idx, table in enumerate(doc.tables, 1):
                content_parts.append(f"\n--- è¡¨æ ¼ {table_idx} ---")
                for row in table.rows:
                    row_text = " | ".join(cell.text.strip() for cell in row.cells)
                    if row_text.strip(" |"):
                        content_parts.append(row_text)
        
        return "\n".join(content_parts)
        
    except Exception as e:
        return f"è¯»å– Word æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"
